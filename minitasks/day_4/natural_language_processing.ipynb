{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing Mini Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** Ties de Kok ([Personal Website](https://www.tiesdekok.com))  \n",
    "**Last updated:** 15 March 2019  \n",
    "**Python version:** Python 3.6 or 3.7   \n",
    "**License:** MIT License  \n",
    "**Credit:** part of these tasks were co-created by Stephan Hollander ([Personal Website](https://www.tilburguniversity.edu/webwijs/show/s.hollander/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Introduction*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will provide you with \"tasks\" that you can try to solve.  \n",
    "\n",
    "Most of what you need is discussed in the tutorial notebooks, the rest you will have to Google (which is an important exercise in itself)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Relevant notebooks*\n",
    "\n",
    "1) [`0_python_basics.ipynb`](https://nbviewer.jupyter.org/github/TiesdeKok/LearnPythonforResearch/blob/master/0_python_basics.ipynb)  \n",
    "\n",
    "\n",
    "2) [`2_handling_data.ipynb`](https://nbviewer.jupyter.org/github/TiesdeKok/LearnPythonforResearch/blob/master/2_handling_data.ipynb)  \n",
    "\n",
    "\n",
    "3) [`NLP_Notebook.ipynb`](https://nbviewer.jupyter.org/github/TiesdeKok/Python_NLP_Tutorial/blob/master/NLP_Notebook.ipynb)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** make sure you have the `limperg-python` environment activated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First steps into NLP<br> ----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this mini-task is to get hands-on experience with handling, cleaning, and analyzing textual data using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Perform basic operations on a sample text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) Load the following text file: `data > example_text.txt` into Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b) Print the first 400 characters of the text file you just loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c) Count the number of times the words `Holmes` and `Watson` are mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c) Use the provided Regular Expression to capture all names following \"Mr.\"  \n",
    "Use this regular expression: `Mr. (.*?)\\W`  \n",
    "**You can play around with this regular expression here: <a href='https://goo.gl/55eMjU'>Test on Pythex.org</a>**\n",
    "\n",
    "**Hint:** use the `re.findall()` function\n",
    "\n",
    "### Bonus task: try to explain to your neighbour what the regular expression is doing (you can use the cheatsheet on Pythex.org for reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d) Load the text into a Spacy object and split it into a list of  sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to evaluate how well it worked by inspecting various elements of the sentence list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus task: why is there a difference between what you see when you run `sentences[1]` versus `print(sentences[1])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main NLP tasks<br> ----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1)** Follow Garcia and Norli (2012) and extract state name counts from MD&As\n",
    "\n",
    "**Task 2)** Create a sentiment score for MD&As based on the Loughran and McDonald (2011) word lists  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References  \n",
    "\n",
    "Garcia, D., & Norli, Ø. (2012). Geographic dispersion and stock returns. Journal of Financial Economics, 106(3), 547-565.  \n",
    "Loughran, T., & McDonald, B. (2011). When is a liability not a liability? Textual analysis, dictionaries, and 10‐Ks. The Journal of Finance, 66(1), 35-65."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering and extracting the MD&A section of a 10-K is quite tricky.  \n",
    "\n",
    "I have therefore included a random selection of 20 pre-processed MDA filings.  \n",
    "\n",
    "In the \"data\" folder you will find a folder called \"MDA_files\". Each file in this folder is an MD&A filing, the filename is the unique identifier.\n",
    "\n",
    "You will also find a file called `MDA_META_DF.xlsx` in the \"data\" folder, this contains the following meta-data for eaching MD&A: (filing date, cik, company name, and link to filing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Extract state name counts from MD&As"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a) Load data into a dictionary with as key the filename and as value the content of the text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files should all be in the following folder:  \n",
    "```\n",
    "os.path.join('data', 'MDA_files')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b) Load state name data into a DataFrame  \n",
    "**Note:** state names are provided in the `state_names.xlsx` file in the \"data\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c) Count the number of times that each U.S. state name is mentioned in each MD&A   \n",
    "**Hint:** save the counts to a list where each entry is a list that contains the following three items: [*filename*, *state_name*, *count*], like this:\n",
    "> [   \n",
    " ['21344_0000021344-16-000050.txt', 'Alabama', 0],  \n",
    " ['21344_0000021344-16-000050.txt', 'Alaska', 0],  \n",
    " ['21344_0000021344-16-000050.txt', 'Arizona', 0],   \n",
    "> ....  \n",
    ">['49071_0000049071-16-000117.txt', 'West Virginia', 0],  \n",
    " ['49071_0000049071-16-000117.txt', 'Wisconsin', 0],  \n",
    " ['49071_0000049071-16-000117.txt', 'Wyoming', 0]   \n",
    " ]   \n",
    " \n",
    "You can verify that it worked by checking whether the the 19th element (i.e. `list[18]`) equals:  \n",
    "> ['21344_0000021344-16-000050.txt', 'Maine', 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d) Convert the list you created in `2c` into a Pandas DataFrame and save it as an Excel sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint:** Use the `columns=[...]` parameter to name the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Create sentiment score based on Loughran and McDonald (2011)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a) Load the Loughran and McDonald master dictionary    \n",
    "**Note:** The Loughran and McDonald dictionary is included in the \"data\" folder: `LoughranMcDonald_MasterDictionary_2014.xlsx `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b) Create two lists: one containing all the negative words and the other one containing all the positive words   \n",
    "**Tip:** I recommend to change all words to lowercase in this step so that you don't need to worry about that later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c) For each MD&A calculate the *total* number of times negative and positive words are mentioned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** make sure you also convert the text to lowercase!\n",
    "\n",
    "**Hint:** save the counts to a list where each entry is a list that contains the following three items: [*filename*, *total pos count*, *total neg count*], like this:\n",
    "> [   \n",
    "    ['21344_0000021344-16-000050.txt', 1166, 2318],   \n",
    "    ['21510_0000021510-16-000074.txt', 606, 1078],  \n",
    "    ['21665_0001628280-16-011343.txt', 516, 1058],      \n",
    "> ....  \n",
    "    ['47217_0000047217-16-000093.txt', 544, 928],  \n",
    "    ['47518_0001214659-16-014806.txt', 482, 974],  \n",
    "    ['49071_0000049071-16-000117.txt', 954, 1636]    \n",
    " ]   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d) Convert the list created in 3c into a Pandas DataFrame  \n",
    "**Hint:** Use the `columns=[...]` parameter to name the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3e) Create a new column with a \"sentiment score\" for each MD&A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following imaginary sentiment score:  \n",
    "$$\\frac{(Num\\ Positive\\ Words - Num\\ Negative\\ Words)}{Sum\\ of Pos\\ and\\ Neg\\ Words}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3f) Use the `MDA_META_DF` file to add the company name, filing date, and CIK to the sentiment dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
